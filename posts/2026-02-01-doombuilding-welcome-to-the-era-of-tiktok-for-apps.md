---
layout: post
title: "Doombuilding - Welcome to the Era of TikTok for Apps"
date: 2026-02-01
author: Michael Kotlikov
categories: [ai, software-development, culture]
tags: [generative-ai, jevons-paradox, productivity, doombuilding, coding]
---

# Doombuilding - Welcome to the era of TikTok for apps

*Michael Kotlikov - February 1, 2026*

> **TL;DR:** Generative AI has made code so cheap to produce that we're proving Jevons paradox right—consuming more development cycles instead of saving them—while mistaking watching an LLM solve problems for actually learning how to solve them ourselves.

We all know the feeling of doomscrolling. You sit down for five minutes of entertainment and suddenly it’s 2 AM, your thumb is cramping, and you’ve consumed 400 hyper-niche videos that you won't remember tomorrow. It feels like engagement, but it’s really just passive consumption on fast-forward.

Recently, I’ve started wondering if generative AI is doing the same thing to coding. Have we entered the short attention span era of work? Welcome to "Doombuilding."

The premise of AI programming is incredible: speed. Projects that used to die on the vine because the activation energy was too high are now getting built in a weekend. We aren't just starting things; we are actually finishing them. The dopamine hits are frequent and intoxicating.

But in this rush of hyper-productivity, we seem to be definitively proving **Jevons paradox** right.

The 19th-century economic theory warns that as technology increases the efficiency with which a resource is used, the total consumption of that resource increases rather than decreases. Now that the "cost" of writing code has plummeted to near zero, we aren't using AI to finish our work early and go to the beach. We are simply jamming *more* code into the same hours. We aren't saving effort; we are consuming development cycles at a record pace to build things we might not even need.

This leads to strange new behaviors. Because code is so cheap to produce, we treat it as disposable.

Are you spending an extra three hours polishing a feature that nobody needs, just because it’s easy to get it over the finish line? Are you nuking your entire codebase on a Saturday morning and rewriting it in a new framework just because Claude suggested it might be cleaner?

We risk filling the world with software equivalents of those single-line npm packages—technically functional, but ultimately shallow and serving little purpose.

There is also a distinct parallel here to the "tutorial trap" or the illusion of classroom competence.

I remember sitting in advanced college math classes, watching the professor solve incredibly complex problems on the board. As chalk flew and equations balanced, I nodded along enthusiastically. Every step made perfect sense in real-time. It was elegant, logical, and obvious. I left the lecture hall feeling like a genius.

Then, I got back to my room, opened the textbook to do the homework, and stared at a blank page for two hours.

I hadn't actually learned how to solve the problems; I had merely recognized the logic of someone *else* solving them perfectly. I mistook observation for understanding.

When an LLM generates 99% of your code in seconds, you are in that lecture hall. You see the `useEffect` hook land in the right spot, you see the API route configured perfectly, and you nod. "Yes, obviously."

But are you learning? When the AI does the heavy lifting, you aren't building the mental muscle memory that comes from debugging a nasty race condition at midnight. You’re just watching the professor on the board.

AI is an undeniably powerful accelerator. But we have to be careful that "Doombuilding" doesn't replace deep work. Just because we *can* build everything doesn't mean we *should*. We need to ensure we aren't just feeding our short attention spans with digital sugar, creating a mountain of finished projects that offer the depth of a fifteen-second dance video.
