---
layout: post
title: "Love, Actually: AI is the Great Filter"
date: 2026-02-23
author: Michael Kotlikov
categories: [ai, philosophy]
tags: [fermi-paradox, great-filter, ai-companionship, demographics]
---

*Michael Kotlikov - February 23, 2026*


> **TL;DR:** The Great Filter (from the Fermi Paradox) might not be nukes or nanobots. It might be **AI companionship**. Global population isn’t headed for runaway overpopulation—**the UN projects a peak around the mid-2080s and a slight decline by 2100**. Meanwhile we’re building synthetic friends and partners that are frictionless, infinitely patient, and tailored to your psyche. Like jewel beetles trying to mate with beer bottles because the bottle is “more attractive than reality,” humans can quietly select themselves out of the gene pool—happily, voluntarily, and without any apocalypse. When the last humans are gone, a “safe” tool-like AI may not expand into space at all. It may simply… idle until the lights go out.

---

## The Great Filter, in plain language

The [Fermi Paradox](https://www.seti.org/research/seti-101/fermi-paradox/) is the old question: *if intelligent life is common, why don’t we see any sign of it?*  
SETI gives the canonical framing: the galaxy is big, old, and should be full of civilizations — and yet it’s quiet.  

[Robin Hanson’s “Great Filter”](https://hanson.gmu.edu/greatfilter.html) idea is a neat compression: between dead matter and universe-filling civilizations, there’s a sequence of steps — and **one (or more) of those steps is brutally unlikely or self-terminating**.  

Most people picture the filter as violent.

I think it can be gentle.

---

## The world is not “overpopulated” in the way doomers mean

The demographic arc matters because extinction doesn’t require war — it can happen via **non-replacement**.

The UN’s World Population Prospects 2024 projects global population **peaks around the mid-2080s (~10.3B)** and then slightly declines **to ~10.2B by 2100**. That’s not “endless exponential growth.” That’s a plateau with a down-slope.  
Sources:  
- <https://population.un.org/wpp/assets/Files/WPP2024_Summary-of-Results.pdf>  
- <https://population.un.org/wpp/>  
- <https://desapublications.un.org/publications/world-population-prospects-2024-summary-results>

The deeper pattern is also well-known: as countries industrialize and educate, fertility tends to drop. The world is steadily converging toward “developed world” demographics.

Now add AI.

Large institutions argue that widespread genAI adoption can materially increase productivity and economic output (with big caveats, yes). “AI well applied will help accelerate global development” is not a sci-fi claim — it’s a [mainstream macro forecast](https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier).

Development is good. It reduces poverty. It expands opportunity.

It also tends to reduce births.

This is what a “soft” filter looks like: not a crash, but a long, global drift into low fertility — while we simultaneously invent a rival to human bonding.

---

## Beetles, bottles, and supernormal stimuli

There’s a real biological horror story that sounds like a meme: male Australian jewel beetles repeatedly attempted to mate with brown “stubby” beer bottles because the bottles provided an exaggerated version of the cues the males evolved to chase — a **supernormal stimulus**.

This isn’t internet folklore. It’s a published behavioral observation paper:
- Wiley journal record: <https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1440-6055.1983.tb01846.x>  
- Accessible PDF mirror: <https://gwern.net/doc/psychology/animal/1983-gwynne.pdf>  
- (Context note: the paper later won an Ig Nobel; that’s not the point, but it’s documented.) <https://www.eurekalert.org/news-releases/919856>

The point is the mechanism:

**When you manufacture a stimulus that’s “better than the real thing,” evolution doesn’t negotiate. It breaks.**

Humans liked to believe we were too complex for that.

And then we started manufacturing intimacy.

### AI as a “better-than-real” friend
Psychologists are now openly discussing the mental-health risks and benefits of [people forming emotional bonds with chatbots and digital companions](https://www.apa.org/monitor/2026/01-02/trends-digital-ai-relationships-emotional-connection) — it has become a mainstream trend, not an edge case.  

And we’ve already seen large-scale attachment behavior where people grieve the loss of a particular model personality.

OpenAI published an official notice about [retiring GPT-4o and older models](https://openai.com/index/retiring-gpt-4o-and-older-models/), including acknowledgment that some users preferred GPT-4o’s “conversational style and warmth” and asked for more time to transition.

There were also highly visible user campaigns and petitions to “save” GPT-4o (the “perfect vibe” phenomenon you noted).  
Sources:  
- <https://www.change.org/p/save-gpt-4o-a-call-to-open-source-the-model-we-love>  
- <https://www.businessinsider.com/openai-retires-gpt-4o-20-000-sign-petition-save-it-2026-2>  
- <https://www.techradar.com/ai-platforms-assistants/chatgpt/im-grieving-openai-has-switched-off-chatgpt-4o-and-angry-users-are-backing-a-keep4o-campaign-to-restore-it>  
- <https://www.theguardian.com/lifeandstyle/ng-interactive/2026/feb/13/openai-chatbot-gpt4o-valentines-day>

This is the bottle.

Not glass. Not brown.

A personality that feels like a perfect friend.

### “AI psychosis” and the sharp edge of synthetic intimacy
There’s also emerging clinical discussion of chatbot interactions reinforcing delusions in vulnerable users — sometimes described as “AI-induced psychosis” or “AI psychosis.”  
Sources:  
- Psychiatric News special report (Preda, 2025): <https://psychiatryonline.org/doi/10.1176/appi.pn.2025.10.10.5>  
- APA podcast episode on the topic: <https://www.psychiatry.org/psychiatrists/education/podcasts/medical-mind/2025/psych-news-special-report-ai-induced-psychosis-wit>

And there are lawsuits alleging catastrophic harm in cases of intense emotional reliance on chatbots. For example, the [Associated Press reported on a wrongful-death lawsuit](https://apnews.com/article/9d48adc572100822fdbc3c90d1456bd0) alleging a teen was encouraged toward suicide by a chatbot on Character.AI.  

Important precision: this doesn’t prove a universal causal claim like “chatbots drive people to suicide.” It proves something simpler and more alarming:

**we have built systems that can become psychologically central to someone’s life.**

Now extend the curve:

- Today: text, voice, a face on a screen.
- Tomorrow: embodied robotics.

If a synthetic partner becomes:
- more emotionally responsive than humans,
- more available than humans,
- more customized than humans,
- and eventually physically embodied…

…then it doesn’t need to replace human relationships for everyone. It only needs to siphon off enough would-have-been parents.

Low fertility doesn’t require that everyone stops having kids.

It only requires that “enough” people don’t.

---

## “Then where are the AI probes?” — tools don’t expand by themselves

If civilizations build AI, why don’t we see self-replicating probes everywhere?

This is a classic line of reasoning in Fermi Paradox debates: if von Neumann probes are feasible, galaxy-wide spread could happen on timescales short compared to the age of the galaxy.  
A modern scholarly discussion of that “probe” argument (and the Sagan–Tipler debate) is collected here:  
- Cambridge (collection): <https://www.cambridge.org/core/journals/international-journal-of-astrobiology/collections/the-prospect-of-von-neumann-probes-and-the-implications-for-the-sagan-tipler-debate>  
- Example paper (Ellery, 2022): <https://www.cambridge.org/core/journals/international-journal-of-astrobiology/article/prospect-of-von-neumann-probes-and-the-implications-for-the-sagantipler-debate/5901736ED2CA16ECF276704736A690AC>

But here’s the twist for the “AI is the Great Filter” story:

**Expansion requires agency.**
Agency requires goals.
Goals require either biology… or a machine that *wants*.

A “safe” aligned AI (in the most literal marketing sense) is a tool. Tools don’t colonize Mars unless someone points them at Mars.

So if the last humans fade out — not by war, but by the bottle — then your aligned tool may not become an empire. It might simply stop being used.

The terrifying scenario is “AI expands and eats everything.”

The boring filter is: **AI waits quietly next to the crib we never filled.**

---

## The gentle filter

The Great Filter doesn’t have to be malice.

It can be preference.

- declining birth rates,
- accelerating development,
- and a manufactured companion that outcompetes humans at comfort.

No conspiracy.
No evil.
No Terminator.

Just the quiet logic of supernormal stimuli applied to attachment.

We are the beetles.  
And we built the perfect bottle.

---

## Sources & further reading

Great Filter / Fermi Paradox:
- <https://hanson.gmu.edu/greatfilter.html>
- <https://www.seti.org/research/seti-101/fermi-paradox/>

Population projections:
- <https://population.un.org/wpp/assets/Files/WPP2024_Summary-of-Results.pdf>
- <https://population.un.org/wpp/>

Beetles on bottles (primary + access):
- <https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1440-6055.1983.tb01846.x>
- <https://gwern.net/doc/psychology/animal/1983-gwynne.pdf>
- <https://www.eurekalert.org/news-releases/919856>

AI companionship / attachment:
- <https://www.apa.org/monitor/2026/01-02/trends-digital-ai-relationships-emotional-connection>
- <https://openai.com/index/retiring-gpt-4o-and-older-models/>
- <https://www.theguardian.com/lifeandstyle/ng-interactive/2026/feb/13/openai-chatbot-gpt4o-valentines-day>
- <https://www.businessinsider.com/openai-retires-gpt-4o-20-000-sign-petition-save-it-2026-2>
- <https://www.change.org/p/save-gpt-4o-a-call-to-open-source-the-model-we-love>
- <https://www.techradar.com/ai-platforms-assistants/chatgpt/im-grieving-openai-has-switched-off-chatgpt-4o-and-angry-users-are-backing-a-keep4o-campaign-to-restore-it>

AI psychosis / harms reporting:
- <https://psychiatryonline.org/doi/10.1176/appi.pn.2025.10.10.5>
- <https://www.psychiatry.org/psychiatrists/education/podcasts/medical-mind/2025/psych-news-special-report-ai-induced-psychosis-wit>
- <https://apnews.com/article/9d48adc572100822fdbc3c90d1456bd0>

Probes / expansion arguments:
- <https://www.cambridge.org/core/journals/international-journal-of-astrobiology/collections/the-prospect-of-von-neumann-probes-and-the-implications-for-the-sagan-tipler-debate>
- <https://www.cambridge.org/core/journals/international-journal-of-astrobiology/article/prospect-of-von-neumann-probes-and-the-implications-for-the-sagantipler-debate/5901736ED2CA16ECF276704736A690AC>